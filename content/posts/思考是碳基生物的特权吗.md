---
title: 思考是碳基生物的特权吗？
tags:
  - AI
  - 计算机
  - 哲学
  - 自然
date: 2025-05-21T23:55:00
draft: false
toc: true
slug: thinking-privilege
featured: true
---

我一直不认为 AI 的「思考」是真正的「思考」，对于 AI 是否有主观性和主体性这个问题[^1]，我也一直很难接受肯定的答案。这个问题其实已经有不少人讨论过了，甚至形成了「人工智能哲学」这一门哲学的分支。今天的文章就来聊一聊前人有关人工智能的理论，以及我自己对 AI 能不能以及在未来能不能像人类一样思考这个问题有何看法。<!--more-->

## 什么样的机器才有智慧？

我很不认可各类媒体上神化，甚至神秘化人工智能的言论，原因在于，我不认为人工的智能是真正的智能。我认为计算机实现了一种名为「人工智能」的新智能，或许人们意图使用它模拟人类的智能，但至少就目前来说，这种智能与人类的智能相差甚远。

在深入这个话题之前，我们先要定义：什么是智能？

这个问题其实很难回答，因为在不同的语境下，智能有着不同的定义。我们可以承认的是，地球上的大部分生物都拥有一种智慧，即使是植物，也在漫长的进化过程中学会了使用根系和信号素来进行沟通。

中文的智能和智慧似乎有差别，但英文都写作 intelligence。在中文语境下谈到「智能」一词时，大部分人应该会先想到「高新技术」。所以，我们不妨把「智能」定义为「机器显示出来的智慧」，或者说「人通过制造机器而展现出来的智慧」「人的智慧在物理世界中的投射」。

那么，什么样的机器才有智慧，什么样的技术才能制造出智能？这里其实会分化出两种观点：

1. **结构决定智能**。机器一定要有一定的物理结构或逻辑结构（如代码逻辑）来实现智能，也就是说，工程师必须要了解智能的原理和思考的过程，并让机器模拟这一过程。
2. **表现决定智能**。这是大多数人的观点。如果一个机器表现出了和人类似的智能，可以被称作「聪明的」，那么这个机器就拥有了智能，无论其内部结构如何。

我们先来看第二种智能。

## 图灵测试和中文屋

几乎没有人不知道「图灵测试」。图灵测试的基本逻辑类似于「如果它看起来像鸭子、游泳像鸭子、叫声像鸭子，那么它可能就是只鸭子。」当人类无法分辨出机器和人的区别时，那这台机器和人也就没有太多区别了。

很少被人提及的是，图灵测试也受到了批评。Stuart J. Russell 和彼得·诺维格这样写道：

> 航空工程学的教科书并没有将领域目标定义为“制造能像鸽子一样准确飞行的机器，直到能骗过鸽子”。

这句话想表达的观点是：图灵测试只能保证机器足够「人性化」，一台通过图灵测试的机器施展的可以是彻头彻尾的骗术，而无需实现结构上的智能。

另一个有趣的假设叫做「中文屋」。我还在 Backrooms 创作的时候，有人写过一篇「欧语屋」，灵感就源于此。简单来说，中文屋就是「一个人在封闭的房间内按照一定的机器指示抄写汉字并将纸片传递给房间外面的人，而外面的人以为房间里有一个流利的中文使用者」，很显然，房间、卡片和屋内人所遵从的指示都没有真正的心智，所以中文屋不拥有心智。

我意识到这也是我看待大语言模型的方式：基于神经网络的大语言模型通过概率运算，算出了问题的答案，这在结构上并没有真正地实现了智能，毕竟人工智能也只是由确定的计算单元、层级、参数和各类函数组成的。不太准确地讲，大语言模型施展的就是一种「骗术」。

图灵测试的鸭子逻辑当然也有道理。鸭子测试实际上是一种归纳推理，甚至符合「奥卡姆剃刀」原理，在归纳时使用鸭子测试是简单直接的。

> 学者詹姆士·摩尔将图灵测试形容为鸭子测试：“图灵测试的场景符合奥卡姆剃刀，无法区别的对象应视作相同，仅当观测到有差异时再进行区分。我们把图灵测试看作一种让测试者给被测试对象打标签的认证过程：‘如果它看起来像鸭子，走起来像鸭子，叫起来也像鸭子，我们就给它打上鸭子的标签。’”[^3]

一些人认为，**既然我们都没法证明一个人是否真的在思考，那我们不需要证明机器真的在思考，就能认为机器拥有智能**。

## 学习和智能可以被准确描述吗？

现在我们来看更麻烦的第一种智能，也就是在结构上实现的智能。如果要在结构上实现智能，我们必须对思考、学习、语言组织等过程进行深度的解构，用机器能执行的方式准确地描述。

这听起来就很难，我们不妨看看前人是怎么看的吧。

### AI 奠基人的假设

1956 年，一群数学家、科学家聚在一起讨论在当时还非常新颖的技术，他们创造了「人工智能」这个概念和词汇，人工智能如今成为一个庞大的研究领域，也归功于这次会议。这次会议被称作达特茅斯会议（Dartmouth Workshop）。他们在会议上提议：[^2]

> We propose that a 2-month, 10-man study of artificial intelligence be carried out during the summer of 1956 at Dartmouth College in Hanover, New Hampshire. The study is to proceed on the basis of the conjecture that ==every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it.== An attempt will be made to find how to make machines use language, form abstractions and concepts, solve kinds of problems now reserved for humans, and improve themselves. We think that a significant advance can be made in one or more of these problems if a carefully selected group of scientists work on it together for a summer.

简单来说，他们提议为期两个月的研究，研究基于这样的假设进行：==如果可以精确的描述学习的所有面向，或智能的任何其它特征，一个机器就可以被制造来模拟它==。他们想要在研究中找到让机器使用语言、创造抽象和概念的方法。

请注意原文使用的词是 conjecture，意思是 an opinion or conclusion formed on the basis of incomplete information（基于不完整信息的观点和结论）。达特茅斯会议提出了很多对后世影响深远的想法，塑造了学界对人工智能的基本认知（包括这一假设），但讨论和研究都是基于这个未被证实的假设进行的，并且没有直接产出实际性的成果。

也就是说，学习的所有面向和智能的任何其他特征，究竟能否被精确描述，能否被机器模拟，在这里还没有给出理论支撑。然而，有不少关于人工智能的讨论，都是基于这一假设的。

### 思考或许是生物化学反应

前文所述的中文屋，其实是对「物理符号系统」的一个模拟。一些学者认为人的思维其实是处理符号的过程，只要建立一个物理符号系统，就能够模拟智能。你可以说，这是符号主义观点中的人工智能。

Nils Nilsson 对物理符号系统进行了抨击，其论述中有一些论点，也可以被用于反驳不基于符号系统的人工智能。

> 1. “ ‘物理符号系统假设’缺少了符号基础”这一错误主张被认为是通用智慧行为的必要条件。
> 2. 普遍认为，AI 需要非符号处理（例如，联结主义架构可以提供非符号处理）。
> 3. 普遍认为，**大脑根本不是一台计算机**，目前所理解的计算并没有为智力提供合适的模型。
> 4. 最后，**有些人也相信大脑本质上是无意识的，大部分发生的事情是化学反应，人类的智慧行为类似于蚁群所显示的智慧行为**。

我想谈的重点在最后两条。Nilsson 指出，大脑根本不是一台计算机，大脑可能在本质上是无意识的，思考很大程度上是化学反应。尽管已经有生物计算机的研究正在进行，甚至有了一些产品出现，但至少目前的大语言模型和其他类型的人工智能，都不是运行在生物计算机上的，**电子计算机还无力实现基于生物化学反应的思考过程**。

### 人造的生物智能

前两个小节中，我们明确了：

1. 「智慧行为能被准确描述并被机器模拟」这一假设被广泛使用，但似乎未被证实；
2. 智慧行为很可能不只是「计算」，不只是理性的分析和推理，可能还包括了生物的化学反应，包括了心理上的无意识；或者说，智慧行为根本就不是计算，而是更复杂的生物过程。

尽管目前的大语言模型，在表现上似乎已经实现了智能，甚至在很多方面表现得超过了人类，但在结构上，很难说包括大语言模型在内的各种人工智能，真的拥有和生物类似的智慧。这也是为什么我在本文一开始就表示，==我认为人们用计算机创造了一种新智能，而非用计算机模拟了生物的智能==。

我并不认为人工智能鼻祖们提出的假设就是错误的，但就目前来看，我们对机器的理解和对智能的理解，都不足以让我们准确描述智能，用机器实现智能。==如果要让人工智能进一步接近生物智能，我们需要对生物的思考方式进行更深入的研究，并且让实现人工智能的机器技术和工程方法不局限于「计算」==。

既然人能模仿自然造出钻石，那为什么不相信人能模仿自然造出智慧呢？只不过人造钻石也有缺陷，人造的生物智能也是很遥远的事情了。

## 思考可以发生在物理世界吗？

之前在讨论 AI 的时候，我做出了一个类似于「猴子打字机」的假设。

在这之前需要先补充一些计算机系统的基础知识：编程语言被编译成可执行的程序的过程，其实是在将源代码编译成机器指令的过程；机器指令定义了计算机上最基础的操作。举个例子，`x = x + 1` 这个简单的自增操作，至少需要三条机器指令来完成——将 `x` 的值写入一个寄存器；寄存器自增；将寄存器中的值写回内存。

任何计算机程序，在硬件底层，都是这样完成操作的。大部分人应该都知道计算机实际上只能操作 0 和 1，AI 也一样，大语言模型实际上也只是在不断地将 0 变成 1，将 1 变成 0 而已。

那么问题来了：**如果操作 0 和 1 的不是机器，而是猴子，甚至是人呢？**

尽管大语言模型可能需要运行上千亿条指令才能算出答案，但这样的过程总归是有迹可循的，计算机算法的一个基本特性就是「有穷性」。如果列出大语言模型在运行时执行的所有机器指令（这些指令是极其抽象、原始的，不像 C 语言这样的高级程序设计语言那样容易理解其逻辑结构），并让一只受到良好训练的猴子和一个人根据这些指令进行计算，操作 0 和 1，最后将计算结果编码，就得到了大语言模型所生成的答案。

你可以理解为，这只猴子和这个人，用自己的大脑和必要的计算工具运行了一个大语言模型实例。

猴子是有意识的，但其思考能力要逊色于人类；人是有意识的，也显然比猴子更有智慧。然而，无论智力水平如何，猴子和人都通过机器的计算「思考」得出了一个问题的答案。也就是说，猴子和人在没有思考的情况下完成了「思考」，而且这种「思考」与智力水平无关。

那么，这样的「思考」真的是思考吗？这样的「思考」是发生在物理世界的，因为它不需要被人或猴子的意识理解就能进行，所以可以交给机器来做。相信基于二进制和机器指令操作的计算机能够「思考」，就是在相信「思考」无需「意识」也能进行，也就是在相信「思考是物质的」。

当然，这似乎也没什么问题，因为从唯物主义的视角来看，物质决定意识，思考就是建立在物质基础上的。生物结构是物质的，而由物质构成的我们拥有思考能力。只不过，这里提到的「物质的思考」略有不同，因为它同时也是「概念的」，它可以发生在人和猴子的脑中，但无需被大脑理解就能进行。

## 人类对智慧的理解足够深入吗？

人们发现 AI 会骗人，并感到恐惧；人们发现 AI 会出现幻觉，并觉得它很蠢；人们发现 AI 会迎合人类的想法，并认为它虚伪……

然而，「骗人」「蠢」「虚伪」，都是对「表现」的评价，是人类投射在无生命物体上的情绪和想法。在结构上，AI 从来就不会骗人也没有当伪君子的能力，在内部结构中发生的事情，只是复杂的算法认为这个「让人类觉得是骗人或虚伪或蠢」的字符串，是在当前语境和参数下，概率最高的结果。**计算机程序缺少判断结果是否虚假、是否愚蠢的结构**。

即使是看似领先时代的神经网络模型，甚至是 GPT 使用的另一种神经网络模型 Transformer，最终也是一个字一个字输出的概率运算。基于数理统计和概率论的逻辑结构，能够模拟涉及到复杂化学反应和无意识活动的生物结构吗？我不这么认为。

当然，「复杂的化学反应和无意识活动」也是一个非常简化的、浅薄的对智慧的理解。我认为人类制造出真正意义上的生物智能不是没有可能，只是很难、很复杂，并且目前的任何一种人工智能，都还达不到那样的高度。

模拟生物智能，目前看来，还是存在于人类认知以外的东西。

[^1]: 值得一提的是，主体性和主观性在英文里对应的是同一个词「Subjectivity」，在维基百科上同属于一个词条，所以直到现在我也还是非常疑惑主观性和主体性的区别，不过这是题外话了。
[^2]: [Dartmouth workshop - Wikipedia](https://en.wikipedia.org/wiki/Dartmouth_workshop)
[^3]: 参见：[鸭子测试 - Wikipedia](https://zh.wikipedia.org/zh-cn/鸭子测试)