---
title: 思考是碳基生物的特权吗？
subtitle: 
tags:
  - AI
  - 计算机
  - 哲学
related_cards: 
mentioned_books: 
date: 2025-04-27T23:41:00
categories: 
banner: 
draft: true
toc: true
slug: is-thinking-animals-privilege

---

我一直不认为 AI 的「思考」是真正的「思考」，对于 AI 是否有主观性和主体性这个问题[^1]，我也一直很难接受肯定的答案。这个问题其实已经有不少人讨论过了，甚至形成了「人工智能哲学」这一门哲学的分支。今天的文章就来聊一聊前人有关人工智能的理论，以及我自己对 AI 能不能以及在未来能不能像人类一样思考这个问题有何看法。<!--more-->

## 机器能够模拟智能吗？

我很不认可各类媒体上神化，甚至神秘化人工智能的言论，原因在于，我不认为人工的智能是真正的智能。我认为计算机创造了一种名为「人工智能」的新智能，或许人们意图使用它模拟人类的智能，但至少就目前来说，这种智能与人类的智能相差甚远。

### 什么是智能？

这个问题其实很难回答，因为在不同的语境下，智能有着不同的定义。我们可以承认的是，地球上的大部分生物都拥有一种智慧（intelligence），即使是植物也在漫长的进化过程中学会了使用根系和信号素来进行沟通。中文中的智能和智慧似乎有差别，但英文都写作 intelligence，在中文中谈到「智能」一词时，大部分人应该会先想到「高新技术」。所以，我们不妨把「智能」定义为「机器显示出来的智慧」。

那么，什么样的机器才有智慧，什么样的技术才能制造出智能？这里其实会分化出两种观点：

1. **结构决定智能**。机器一定要有一定的物理结构或逻辑结构（如代码逻辑）来实现智能，也就是说，工程师必须要了解智能的原理和思考的过程，并让机器模拟这一过程。
2. **表现决定智能**。这是大多数人的观点。如果一个机器表现出了和人类似的智能，可以被称作「聪明的」，那么这个机器就拥有了智能，无论其内部结构如何。

我们先来看第二种智能。

### 图灵测试和中文屋

几乎没有人不知道「图灵测试」。图灵测试的基本逻辑类似于「如果它看起来像鸭子、游泳像鸭子、叫声像鸭子，那么它可能就是只鸭子。」当人类无法分辨出机器和人的区别时，那这台机器和人也就没有太多区别了。

很少被人提及的是，图灵测试也受到了批评。Stuart J. Russell 和彼得·诺维格这样写道：

> 航空工程学的教科书并没有将领域目标定义为‘制造能像鸽子一样准确飞行的机器，直到能骗过鸽子。

这句话想表达的观点是：图灵测试只能保证机器足够「人性化」，一台通过图灵测试的机器施展的可以是彻头彻尾的骗术，而无需拥有结构上的智能。

另一个有趣的假设叫做「中文屋」。我还在 Backrooms 创作的时候，有人写过一篇「欧语屋」，灵感就源于此。简单来说，中文屋就是「一个人在封闭的房间内按照一定的机器指示抄写汉字并将纸片传递给房间外面的人，而外面的人以为房间里有一个流利的中文使用者」，很显然，房间、卡片和屋内人所遵从的指示都没有真正的心智，所以中文屋不拥有心智。

我意识到这也是我看待大语言模型的方式：基于神经网络的大语言模型通过概率运算，算出了问题的答案，这在结构上并没有真正地实现了智能，毕竟人工智能也只是由确定的神经元、层级、参数和各类函数组成的。不太准确地讲，大语言模型施展的就是一种「骗术」。

---

这么看来，机器能否模拟智能，这个问题的主要分歧在于，个体认为智能是结构决定的，还是表现决定的。不过我打算先把这个问题放一放，下一节先来谈一谈如何模拟智能，无论是从结构上模拟，还是从形式上模拟。

## 怎样模拟智能？

### 学习和智能可以被准确描述吗？

1956 年，一群数学家、科学家聚在一起讨论人工智能，他们其中的一些人在如今被认为是人工智能的创始者。他们在会议上提议：[^2]

> We propose that a 2-month, 10-man study of artificial intelligence be carried out during the summer of 1956 at Dartmouth College in [Hanover, New Hampshire](https://en.wikipedia.org/wiki/Hanover,_New_Hampshire "Hanover, New Hampshire"). The study is to proceed on the basis of the conjecture that ==every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it.== An attempt will be made to find how to make machines use language, form abstractions and concepts, solve kinds of problems now reserved for humans, and improve themselves. We think that a significant advance can be made in one or more of these problems if a carefully selected group of scientists work on it together for a summer.

简单来说，他们提议为期两个月的研究，研究基于这样的推测进行：==如果可以精确的描述学习的所有面向，或智能的任何其它特征，一个机器就可以被制造来模拟它==。[^3]他们想要在研究中找到让机器使用语言、创造抽象和概念的方法。

请注意原文使用的词是 conjecture，意思是 an opinion or conclusion formed on the basis of incomplete information（基于不完整信息的观点和结论）。达特茅斯会议似乎提出了很多有意思的想法，但讨论和研究都是基于这个未被证实的假设进行的，并且没有产出什么实际性的成果。

也就是说，学习的所有面向和智能的任何其他特征，究竟能否被精确描述，能否被机器模拟，在这里还没有给出理论支撑。然而，有不少关于人工智能的讨论，都是基于这一假设的。

### 思考或许是生物化学反应

前文所述的中文屋，其实是对「物理符号系统」的一个模拟。一些学者认为人的思维其实是处理符号的过程，只要建立一个物理符号系统，就能够模拟智能。你可以说，这是符号主义的人工智能。对于物理符号系统的抨击，其实也适用于其他类型的人工智能：

> 尼尔斯·尼尔森（Nils Nilsson）提出了四个抨击物理符号系统假设的主要“论题”或依据。
>
> 1. “ ‘物理符号系统假设’缺少了符号基础”这一错误主张被认为是通用智慧行为的必要条件。
> 2. 普遍认为，**AI 需要非符号处理**（例如，联结主义架构可以提供非符号处理）。
> 3. 普遍认为，**大脑根本不是一台计算机**，目前所理解的计算并没有为智力提供合适的模型。
> 4. 最后，**有些人也相信大脑本质上是无意识的，大部分发生的事情是化学反应，人类的智慧行为类似于蚁群所显示的智慧行为**。[^4]

尼尔森指出，大脑根本不是一台计算机，大脑本质是无意识的，大部分发生的事情时化学反应。尽管已经有生物计算机的研究正在进行，甚至有了一些产品出现，但至少目前的大语言模型和其他类型的人工智能，都不是运行在生物计算机上的。

这种观点认为，二进制的电子计算机还不能模拟人脑。

### 物质与意识

### 发生在物理世界的思考

[^1]: 值得一提的是，主体性和主观性在英文里对应的是同一个词「Subjectivity」，所以直到现在我也还是非常疑惑主观性和主体性的区别，不过这是题外话了。
[^2]: [Dartmouth workshop - Wikipedia](https://en.wikipedia.org/wiki/Dartmouth_workshop)