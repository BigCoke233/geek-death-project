---
title: 稻草人周刊 Vol.50
subtitle:
tags:
categories: 稻草人周刊
date: 2025-09-29T10:41:00
draft: true
toc: true
banner:
endnotes:
---



<!--more-->

---

## ↯ · 当下

## ⋈︎ · 连接

### 大模型为什么因为海马 Emoji 发疯？

> [!note] 📜
> [Why do LLMs freak out over the seahorse emoji?](https://vgel.me/posts/seahorse/)

作者发现，如果问大语言模型（无论是 Claude、ChatGPT、Gemini 还是其他模型）是否存在有「海马」的 Emoji 字符，他们都会回答「有」，然后尝试给出这个他们认为存在的海马 Emoji。实际上，Unicode 里面并没有海马这个 Emoji。这些模型要么在中途发现了自己的错误，改口说不存在海马 Emoji，要么执拗地给出一个不存在的 Emoji 字符，要么在意识不到自己错误的情况下一直输出，比如 GPT-5 的回答：

![](https://image.guhub.cn/uPic/2025/10/Rr4a6Y.png)

作者在后文用 [logit lens](https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens) 这个方法获取了模型的 `lm_head`，`lm_head` 一般在最后一层的输出使用（层应该是指神经网络的层级），可以通过 `lm_head` 推测模型是如何给出某个回答的。简单来说，模型在输出 Emoji 字符的时候，能在 logit 中看到对应的单词和 `ĠðŁ` 这个 Emoji 字节前缀。如果要输出马的 Emoji，token 里就会有 `horse + emoji` 的组合，而被问及海马 Emoji 时，模型的 token 是 `seahorse + emoji`，一个不存在的字符。

由于模型只有在输出之后才有可能意识到海马 Emoji 不存在，所以几乎所有的模型在一开始都会非常肯定地表示海马 Emoji 存在。作者猜测这是模型的强化学习（reinforcement learning）导致的。

## ⁂ · 星群

